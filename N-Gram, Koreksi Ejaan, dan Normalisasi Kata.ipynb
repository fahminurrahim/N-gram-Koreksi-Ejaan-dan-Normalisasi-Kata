{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['Fahmi', 'adalah', 'anak', 'yang', 'rajin']\n",
      "2-gram:  ['Fahmi adalah', 'adalah anak', 'anak yang', 'yang rajin']\n",
      "3-gram:  ['Fahmi adalah anak', 'adalah anak yang', 'anak yang rajin']\n"
     ]
    }
   ],
   "source": [
    "# memasukan library\n",
    "from textblob import TextBlob\n",
    " \n",
    "# Membuat fungsi untuk n-gram terhadap kalimat.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = TextBlob(data).ngrams(num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "# Memasukan kalimat yang diinginkan \n",
    "data = 'Fahmi adalah anak yang rajin'\n",
    "\n",
    "# menampilkan N-gram sesuai dengan jumlah yang diinginkan\n",
    "print(\"1-gram: \", extract_ngrams(data, 1))\n",
    "print(\"2-gram: \", extract_ngrams(data, 2))\n",
    "print(\"3-gram: \", extract_ngrams(data, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kata typo :  tiduuur\n",
      "koreksi :  tidur\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower()) \n",
    "\n",
    "WORDS = Counter(words(open('katadasar.txt').read()))\n",
    "\n",
    "def P(word, N=sum(WORDS.values())):\n",
    "    # \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word):\n",
    "    # \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word):\n",
    "    # \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words):\n",
    "    # \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    # \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)] # [('', 'kemarin'), ('k', 'emarin'), ('ke', 'marin'), dst]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R] # ['emarin', 'kmarin', 'kearin', dst]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1] # ['ekmarin', 'kmearin', 'keamrin', dst]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters] # ['aemarin', 'bemarin', 'cemarin', dst]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters] # ['akemarin', 'bkemarin', 'ckemarin', dst]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word):\n",
    "    # \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "kata = 'tiduuur'\n",
    "print('kata typo : ', kata)\n",
    "print('koreksi : ', correction(kata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
